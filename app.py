"""Streamlit interface for the Akiya-Lens residual model.

This application follows the specification in ``docs/æ®‹å·®ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ—ãƒªè¨­è¨ˆä»•æ§˜.md``.
ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ ``docs/æ®‹å·®ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ—ãƒªè¨­è¨ˆä»•æ§˜.md`` ã®ä»•æ§˜ã«å¾“ã„ã¾ã™ã€‚
ãƒã‚¹ã‚¿ãƒ¼ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + æ®‹å·®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å†æ§‹ç¯‰ã—ã€
ãƒªã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªã€äºˆæ¸¬ã€SHAPç”±æ¥ã®èª¬æ˜ã‚’å«ã‚€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªå¸‚ç”ºæ‘ãƒãƒƒãƒ—ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚

ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ä¾å­˜é–¢ä¿‚ã‚„
æˆæœç‰©ï¼ˆCatBoostãƒ¢ãƒ‡ãƒ«ã€GeoJSONã€SHAPå€¤ï¼‰ãŒæ¬ è½ã—ã¦ã„ã‚‹å ´åˆã§ã‚‚ã€é©åˆ‡ã«æ©Ÿèƒ½ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st

try:  # Optional imports â€“ app remains usable without them
    import folium
    from folium import features
    from branca.colormap import linear as branca_linear
    from branca.element import MacroElement, Template
    from streamlit_folium import st_folium
except ImportError:  # pragma: no cover - handled gracefully in UI
    folium = None
    features = None
    branca_linear = None
    MacroElement = None
    Template = None
    st_folium = None

try:
    from catboost import CatBoostRegressor, Pool
except ImportError:  # pragma: no cover - handled gracefully in UI
    CatBoostRegressor = None  # type: ignore
    Pool = None  # type: ignore


# ---------------------------------------------------------------------------
# Paths & constants
# ---------------------------------------------------------------------------

REPO_ROOT = Path(__file__).resolve().parent
DATA_PATH = REPO_ROOT / "data/processed/features_master__wide__v1.csv"
GEOJSON_PATH = REPO_ROOT / "data/geojson/municipalities.geojson"
MODEL_PATH = REPO_ROOT / "models/catboost_residual_model.cbm"
METRICS_PATH = REPO_ROOT / "data/processed/model_metrics.json"

DEFAULT_TOLERANCE = 0.1  # percentage point threshold for "æ¨ªã°ã„"
MAP_OPTIONS = (
    "4æ®µéšãƒªã‚¹ã‚¯",
    "2023å¹´ç©ºãå®¶ç‡ï¼ˆå®Ÿæ¸¬ï¼‰",
    "2023å¹´ç©ºãå®¶ç‡ï¼ˆäºˆæ¸¬ï¼‰",
    "æ®‹å·®ï¼ˆå®Ÿæ¸¬âˆ’äºˆæ¸¬ï¼‰",
)

RISK_COLORS = {
    "èµ¤(æœ€å„ªå…ˆ)": "#d73027",
    "ã‚ªãƒ¬ãƒ³ã‚¸(æ³¨æ„)": "#fc8d59",
    "é»„(è­¦æˆ’)": "#fee08b",
    "ç·‘(ä½)": "#1a9850",
}

NAN_COLOR = "#d9d9d9"


# ---------------------------------------------------------------------------
# Data loading utilities
# ---------------------------------------------------------------------------


def _normalise_columns(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [c.lstrip("\ufeff") for c in df.columns]
    return df


@st.cache_data(show_spinner=False)
def load_features(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
    df = pd.read_csv(path)
    df = _normalise_columns(df)
    df["å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰"] = (
        df["å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰"]
        .astype(str)
        .str.replace(r"\.0$", "", regex=True)
        .str.zfill(5)
    )
    return df


@st.cache_data(show_spinner=False)
def load_geojson(path: Path) -> Optional[dict[str, Any]]:
    if not path.exists():
        return None
    with path.open("r", encoding="utf-8") as handle:
        return json.load(handle)


@st.cache_data(show_spinner=False)
def load_model_metrics(path: Path) -> Dict[str, Any]:
    if not path.exists():
        return {}
    with path.open("r", encoding="utf-8") as handle:
        return json.load(handle)


@st.cache_resource(show_spinner=False)
def load_catboost_model(path: Path) -> Optional[CatBoostRegressor]:
    if CatBoostRegressor is None:
        return None
    if not path.exists():
        return None
    model = CatBoostRegressor()
    model.load_model(str(path))
    return model


# ---------------------------------------------------------------------------
# Feature utilities
# ---------------------------------------------------------------------------


def _get_numeric_series(df: pd.DataFrame, column: str) -> pd.Series:
    if column not in df.columns:
        return pd.Series(np.nan, index=df.index, dtype="float64")

    series = df[column]
    if pd.api.types.is_numeric_dtype(series):
        return pd.to_numeric(series, errors="coerce")

    cleaned = (
        series.astype(str)
        .str.replace(",", "", regex=False)
        .str.replace("%", "", regex=False)
        .str.replace("â€°", "", regex=False)
    )
    return pd.to_numeric(cleaned, errors="coerce")


def build_model_feature_matrix(
    df: pd.DataFrame, feature_names: Iterable[str]
) -> Tuple[pd.DataFrame, List[str]]:
    feature_list = list(feature_names)
    matrix = pd.DataFrame(index=df.index)
    missing: List[str] = []

    for name in feature_list:
        if name in df.columns:
            series = df[name]
            if pd.api.types.is_numeric_dtype(series):
                matrix[name] = series
            else:
                numeric = (
                    series.astype(str)
                    .str.replace(",", "", regex=False)
                    .str.replace("%", "", regex=False)
                    .str.replace("â€°", "", regex=False)
                )
                numeric = pd.to_numeric(numeric, errors="coerce")
                if numeric.notna().sum() >= series.notna().sum() * 0.5:
                    matrix[name] = numeric
                else:
                    matrix[name] = series
        else:
            missing.append(name)
            matrix[name] = pd.Series(np.nan, index=df.index)

    return matrix[feature_list], missing


# ---------------------------------------------------------------------------
# Prediction & SHAP utilities
# ---------------------------------------------------------------------------


def _fit_baseline(baseline: pd.Series, target: pd.Series) -> tuple[float, float]:
    valid_mask = baseline.notna() & target.notna()
    if valid_mask.sum() < 2:
        return 0.0, 0.0
    x = baseline.loc[valid_mask].to_numpy(dtype=float)
    y = target.loc[valid_mask].to_numpy(dtype=float)
    slope, intercept = np.polyfit(x, y, 1)
    return float(slope), float(intercept)


def compute_predictions(
    df: pd.DataFrame,
    model: Optional[CatBoostRegressor],
) -> tuple[pd.DataFrame, Optional[pd.DataFrame], List[str]]:
    messages: List[str] = []

    vac18 = _get_numeric_series(df, "ç©ºãå®¶ç‡_2018")
    vac23 = _get_numeric_series(df, "ç©ºãå®¶ç‡_2023")
    delta_observed = vac23 - vac18

    slope, intercept = _fit_baseline(vac18, delta_observed)
    base_pred = vac18 * slope + intercept

    feature_matrix: Optional[pd.DataFrame] = None
    resid_pred = pd.Series(0.0, index=df.index, dtype=float)

    if model is not None and hasattr(model, "feature_names_"):
        feature_names = list(model.feature_names_)
        if feature_names:
            feature_matrix, missing = build_model_feature_matrix(df, feature_names)
            if missing:
                messages.append(
                    "å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ä½¿ç”¨ã—ãŸåˆ—ãŒä¸€éƒ¨è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: "
                    + ", ".join(missing[:5])
                    + ("..." if len(missing) > 5 else "")
                )
            try:
                resid_pred = pd.Series(
                    model.predict(feature_matrix),
                    index=feature_matrix.index,
                    dtype=float,
                )
            except Exception as exc:  # pragma: no cover - defensive
                messages.append(f"CatBoostäºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                resid_pred = pd.Series(0.0, index=df.index, dtype=float)
                feature_matrix = None
        else:
            messages.append("CatBoostãƒ¢ãƒ‡ãƒ«ã«ç‰¹å¾´é‡åãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        messages.append(
            "CatBoostãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã‚ãªã‹ã£ãŸãŸã‚ã€æ®‹å·®è£œæ­£ãªã—ã§è¡¨ç¤ºã—ã¾ã™ã€‚"
        )

    pred_delta = base_pred + resid_pred
    pred_vacancy_2023 = vac18 + pred_delta
    residual_gap = delta_observed - pred_delta

    enriched = df.copy()
    enriched["Î”(23-18)"] = delta_observed
    enriched["baseline_pred_delta"] = base_pred
    enriched["residual_model_pred"] = resid_pred
    enriched["pred_delta"] = pred_delta
    enriched["pred_ç©ºãå®¶ç‡_2023"] = pred_vacancy_2023
    enriched["æ®‹å·®(å®Ÿæ¸¬-äºˆæ¸¬)"] = residual_gap

    return enriched, feature_matrix, messages


def compute_shap_topk(
    model: Optional[CatBoostRegressor],
    features: Optional[pd.DataFrame],
    k: int = 3,
) -> Tuple[dict[str, list[str]], Optional[str]]:
    if model is None or features is None or features.empty or Pool is None:
        return {}, None

    try:
        pool = Pool(features)
        shap_values = model.get_feature_importance(pool, type="ShapValues")
    except Exception as exc:  # pragma: no cover - defensive
        return {}, f"SHAPå€¤ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}"

    shap_matrix = pd.DataFrame(
        shap_values[:, :-1], index=features.index, columns=features.columns
    )

    top_lookup: dict[str, list[str]] = {}
    for idx, row in shap_matrix.iterrows():
        top = row.abs().sort_values(ascending=False).head(k)
        formatted = [f"{feat}: {row[feat]:+.3f}" for feat in top.index]
        top_lookup[str(idx)] = formatted
    return top_lookup, None


# ---------------------------------------------------------------------------
# Risk classification & geo utilities
# ---------------------------------------------------------------------------


def classify_risk(df: pd.DataFrame, tolerance: float) -> pd.DataFrame:
    df = df.copy()
    vac18 = _get_numeric_series(df, "ç©ºãå®¶ç‡_2018")
    vac23 = _get_numeric_series(df, "ç©ºãå®¶ç‡_2023")
    delta = vac23 - vac18

    if vac23.dropna().empty:
        threshold = np.nan
    else:
        threshold = float(np.nanpercentile(vac23.dropna(), 75))

    trend = np.where(
        delta > tolerance, "å¢—", np.where(delta < -tolerance, "æ¸›", "æ¨ªã°ã„")
    )
    high_now = (
        vac23 >= threshold if not np.isnan(threshold) else np.full(len(vac23), False)
    )

    labels = []
    for is_high, trend_value in zip(high_now, trend):
        if is_high and trend_value == "å¢—":
            labels.append("èµ¤(æœ€å„ªå…ˆ)")
        elif is_high:
            labels.append("ã‚ªãƒ¬ãƒ³ã‚¸(æ³¨æ„)")
        elif trend_value == "å¢—":
            labels.append("é»„(è­¦æˆ’)")
        else:
            labels.append("ç·‘(ä½)")

    df["P75_threshold"] = threshold
    df["Î”(23-18)"] = delta
    df["ãƒªã‚¹ã‚¯åŒºåˆ†"] = labels
    df["ãƒˆãƒ¬ãƒ³ãƒ‰"] = trend

    return df


def _format_shap_text(items: Iterable[str]) -> str:
    values = [item for item in items if item]
    if not values:
        return "SHAPæƒ…å ±ãªã—"
    return "<br/>".join(values)


def augment_geojson(
    geojson: Optional[dict[str, Any]],
    df: pd.DataFrame,
    shap_lookup: dict[str, list[str]],
) -> Optional[dict[str, Any]]:
    if geojson is None:
        return None

    geojson_copy = json.loads(json.dumps(geojson))
    dedup_df = (
        df.dropna(subset=["å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰"])
        .drop_duplicates(subset=["å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰"], keep="last")
        .set_index("å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰")
    )
    data_lookup = dedup_df.to_dict("index")

    for feature in geojson_copy.get("features", []):
        props = feature.setdefault("properties", {})
        code = str(props.get("å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰", "")).zfill(5)
        record = data_lookup.get(code)
        props["akiya_code"] = code
        if record is None:
            props["akiya_has_data"] = False
            continue

        props["akiya_has_data"] = True
        props["akiya_name"] = record.get("å¸‚åŒºç”ºæ‘å", "ä¸æ˜")
        props["akiya_vac18"] = _safe_value(record.get("ç©ºãå®¶ç‡_2018"))
        props["akiya_vac23"] = _safe_value(record.get("ç©ºãå®¶ç‡_2023"))
        props["akiya_delta"] = _safe_value(record.get("Î”(23-18)"))
        props["akiya_risk"] = record.get("ãƒªã‚¹ã‚¯åŒºåˆ†")
        props["akiya_pred"] = _safe_value(record.get("pred_ç©ºãå®¶ç‡_2023"))
        props["akiya_residual"] = _safe_value(record.get("æ®‹å·®(å®Ÿæ¸¬-äºˆæ¸¬)"))
        props["akiya_trend"] = record.get("ãƒˆãƒ¬ãƒ³ãƒ‰")
        internal_key = str(record.get("_akiya_internal_index", code))
        shap_items = shap_lookup.get(internal_key, [])
        props["akiya_shap"] = _format_shap_text(shap_items)
        props["akiya_map"] = _safe_value(
            record.get("map_value") if "map_value" in record else np.nan
        )

    return geojson_copy


def _safe_value(value: Any) -> Optional[float]:
    try:
        if value is None or (isinstance(value, float) and np.isnan(value)):
            return None
        return float(value)
    except (TypeError, ValueError):
        return None


def build_map(
    geojson: Optional[dict[str, Any]],
    df: pd.DataFrame,
    map_option: str,
    legend_name: str,
) -> Optional[folium.Map]:
    if geojson is None or folium is None or st_folium is None:
        return None

    m = folium.Map(location=[35.6, 137.8], zoom_start=6, tiles="cartodbpositron")

    def tooltip_fields() -> list[str]:
        return [
            "akiya_name",
            "akiya_vac18",
            "akiya_vac23",
            "akiya_delta",
            "akiya_risk",
            "akiya_trend",
        ]

    tooltip = features.GeoJsonTooltip(
        fields=tooltip_fields(),
        aliases=[
            "è‡ªæ²»ä½“",
            "ç©ºãå®¶ç‡(2018)%",
            "ç©ºãå®¶ç‡(2023)%",
            "Î”(23-18)pt",
            "ãƒªã‚¹ã‚¯åŒºåˆ†",
            "ãƒˆãƒ¬ãƒ³ãƒ‰",
        ],
        localize=True,
        sticky=False,
    )

    popup = features.GeoJsonPopup(
        fields=["akiya_name", "akiya_shap", "akiya_pred", "akiya_residual"],
        aliases=[
            "è‡ªæ²»ä½“",
            "SHAP Top3",
            "äºˆæ¸¬ç©ºãå®¶ç‡(2023)%",
            "æ®‹å·®(å®Ÿæ¸¬-äºˆæ¸¬)pt",
        ],
        localize=True,
    )

    if map_option == "4æ®µéšãƒªã‚¹ã‚¯":
        color_map = RISK_COLORS

        def style_function(feature: dict[str, Any]) -> dict[str, Any]:
            props = feature.get("properties", {})
            if not props.get("akiya_has_data"):
                return {
                    "fillColor": NAN_COLOR,
                    "color": "#666666",
                    "weight": 0.2,
                    "fillOpacity": 0.5,
                }
            risk = props.get("akiya_risk")
            color = color_map.get(risk, NAN_COLOR)
            return {
                "fillColor": color,
                "color": "#4d4d4d",
                "weight": 0.4,
                "fillOpacity": 0.75,
            }

        folium.GeoJson(
            geojson,
            style_function=style_function,
            highlight_function=lambda _: {"weight": 1.5, "color": "#000000"},
            tooltip=tooltip,
            popup=popup,
        ).add_to(m)

        if Template is not None and MacroElement is not None:
            legend_template = """
            {% macro html(this, kwargs) %}
            <div style="position: fixed; bottom: 30px; left: 30px; width: 220px;
                        background-color: #ffffff; border: 1px solid #999999;
                        z-index: 9999; font-size: 13px; padding: 10px;
                        color: #333333; box-shadow: 2px 2px 4px rgba(0,0,0,0.25);">
              <b style="display:block; margin-bottom:6px;">4æ®µéšãƒªã‚¹ã‚¯</b>
              <div style="display:flex; align-items:center; margin-bottom:4px;">
                <span style="display:inline-block;width:14px;height:14px;background:#d73027;border:1px solid #555;"></span>
                <span style="margin-left:8px;">èµ¤(æœ€å„ªå…ˆ)</span>
              </div>
              <div style="display:flex; align-items:center; margin-bottom:4px;">
                <span style="display:inline-block;width:14px;height:14px;background:#fc8d59;border:1px solid #555;"></span>
                <span style="margin-left:8px;">ã‚ªãƒ¬ãƒ³ã‚¸(æ³¨æ„)</span>
              </div>
              <div style="display:flex; align-items:center; margin-bottom:4px;">
                <span style="display:inline-block;width:14px;height:14px;background:#fee08b;border:1px solid #555;"></span>
                <span style="margin-left:8px;">é»„(è­¦æˆ’)</span>
              </div>
              <div style="display:flex; align-items:center;">
                <span style="display:inline-block;width:14px;height:14px;background:#1a9850;border:1px solid #555;"></span>
                <span style="margin-left:8px;">ç·‘(ä½)</span>
              </div>
            </div>
            {% endmacro %}
            """
            legend = MacroElement()
            legend._template = Template(legend_template)
            m.get_root().add_child(legend)
    else:
        values = df["map_value"].dropna().to_numpy(dtype=float)
        if values.size == 0 or branca_linear is None:
            colormap = None
        else:
            vmin, vmax = float(np.min(values)), float(np.max(values))
            if np.isclose(vmin, vmax):
                vmax = vmin + 1e-6
            colormap = branca_linear.YlOrRd_09.scale(vmin, vmax)
            colormap.caption = legend_name
            colormap.add_to(m)

        def style_function(feature: dict[str, Any]) -> dict[str, Any]:
            props = feature.get("properties", {})
            if not props.get("akiya_has_data"):
                return {
                    "fillColor": NAN_COLOR,
                    "color": "#666666",
                    "weight": 0.2,
                    "fillOpacity": 0.5,
                }
            value = props.get("akiya_map")
            if value is None or colormap is None:
                color = NAN_COLOR
            else:
                color = colormap(value)
            return {
                "fillColor": color,
                "color": "#4d4d4d",
                "weight": 0.4,
                "fillOpacity": 0.75,
            }

        folium.GeoJson(
            geojson,
            style_function=style_function,
            highlight_function=lambda _: {"weight": 1.5, "color": "#000000"},
            tooltip=tooltip,
            popup=popup,
        ).add_to(m)

    return m


# ---------------------------------------------------------------------------
# Streamlit layout
# ---------------------------------------------------------------------------


def main() -> None:
    st.set_page_config(page_title="Akiya-Lens", layout="wide")
    st.title("ğŸ  Akiya-Lens æ®‹å·®ãƒ¢ãƒ‡ãƒ«ãƒ“ãƒ¥ãƒ¼ã‚¢")
    st.caption("2018â†’2023 ç©ºãå®¶ç‡ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + æ®‹å·®ãƒ¢ãƒ‡ãƒ«è§£æ")

    try:
        features_df = load_features(DATA_PATH)
    except FileNotFoundError as exc:
        st.error(str(exc))
        return

    geojson = load_geojson(GEOJSON_PATH)
    metrics = load_model_metrics(METRICS_PATH)
    model = load_catboost_model(MODEL_PATH)

    with st.sidebar:
        st.header("è¡¨ç¤ºè¨­å®š")
        tol = st.slider("æ¨ªã°ã„è¨±å®¹å¹… (ï¼…ãƒã‚¤ãƒ³ãƒˆ)", 0.0, 1.0, DEFAULT_TOLERANCE, 0.05)
        map_option = st.selectbox("åœ°å›³ã®è‰²åˆ†ã‘", MAP_OPTIONS)
        if model is None:
            st.warning(
                "CatBoostãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ã¿ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"
            )
        if metrics:
            st.subheader("ãƒ¢ãƒ‡ãƒ«æŒ‡æ¨™")
            cat_metrics = metrics.get("catboost")
            if cat_metrics:
                st.metric("CatBoost RÂ²", f"{cat_metrics.get('r2', np.nan):.3f}")
                st.metric("CatBoost MSE", f"{cat_metrics.get('mse', np.nan):.3f}")

    enriched_df, feature_matrix, info_messages = compute_predictions(features_df, model)
    enriched_df = classify_risk(enriched_df, tol)

    shap_lookup, shap_message = compute_shap_topk(model, feature_matrix)
    if shap_message:
        info_messages.append(shap_message)

    display_df = enriched_df.copy()
    display_df["_akiya_internal_index"] = display_df.index.astype(str)

    if map_option == "2023å¹´ç©ºãå®¶ç‡ï¼ˆå®Ÿæ¸¬ï¼‰":
        display_df["map_value"] = _get_numeric_series(display_df, "ç©ºãå®¶ç‡_2023")
        legend = "2023å¹´ç©ºãå®¶ç‡ (%)"
    elif map_option == "2023å¹´ç©ºãå®¶ç‡ï¼ˆäºˆæ¸¬ï¼‰":
        display_df["map_value"] = display_df.get("pred_ç©ºãå®¶ç‡_2023")
        legend = "äºˆæ¸¬ç©ºãå®¶ç‡ (%)"
    elif map_option == "æ®‹å·®ï¼ˆå®Ÿæ¸¬âˆ’äºˆæ¸¬ï¼‰":
        display_df["map_value"] = display_df.get("æ®‹å·®(å®Ÿæ¸¬-äºˆæ¸¬)")
        legend = "æ®‹å·® (pt)"
    else:
        display_df["map_value"] = np.nan
        legend = ""

    geojson_aug = augment_geojson(geojson, display_df, shap_lookup)
    folium_map = build_map(geojson_aug, display_df, map_option, legend)

    if folium_map is None:
        st.warning("Folium ã¾ãŸã¯ GeoJSON ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€åœ°å›³ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
    else:
        st_folium(folium_map, height=650, use_container_width=True)

    st.subheader("è‡ªæ²»ä½“åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«")
    table_cols = [
        "å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰",
        "å¸‚åŒºç”ºæ‘å",
        "éƒ½é“åºœçœŒå",
        "ç©ºãå®¶ç‡_2018",
        "ç©ºãå®¶ç‡_2023",
        "Î”(23-18)",
        "ãƒªã‚¹ã‚¯åŒºåˆ†",
        "ãƒˆãƒ¬ãƒ³ãƒ‰",
        "pred_ç©ºãå®¶ç‡_2023",
        "æ®‹å·®(å®Ÿæ¸¬-äºˆæ¸¬)",
    ]
    existing_cols = [col for col in table_cols if col in display_df.columns]
    table_data = display_df[existing_cols].copy()
    if "ãƒªã‚¹ã‚¯åŒºåˆ†" in table_data.columns:
        table_data = table_data.sort_values("ãƒªã‚¹ã‚¯åŒºåˆ†")
    st.dataframe(table_data, use_container_width=True)

    if info_messages:
        st.subheader("ãƒ­ã‚° / æ³¨æ„äº‹é …")
        for msg in info_messages:
            if not msg:
                continue
            st.markdown(f"- {msg}")

    st.caption("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: data/processed/features_master__wide__v1.csv ä»–")


if __name__ == "__main__":
    main()
